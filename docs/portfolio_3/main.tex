\documentclass[12pt,oneside,a4paper,parskip=half]{scrbook}

% Sprachanpassung und Grundkonfiguration
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{lmodern}
\usepackage{microtype}      % bessere Umbrüche
\usepackage{csquotes}
\usepackage{hyphenat}       % Zeilenumbruch in \texttt
\usepackage{newunicodechar}
\newunicodechar{ }{\,}      % geschütztes schmales Leerzeichen

% Seitenlayout
\usepackage[a4paper,left=20mm,right=20mm,top=20mm,bottom=25mm]{geometry}
\usepackage{setspace}
\onehalfspacing
\sloppy                     % großzügigere Zeilenumbrüche (vermeidet Overfull hboxes)

% WICHTIG für die Diagramme (auch wenn sie ausgelagert sind)
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}


% Mathematik & Symbole
\usepackage{amsmath,amsfonts,amssymb}

% Tabellen & Grafiken
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{pdflscape}
\usepackage{placeins}
\graphicspath{{./}{./figures/}}

% Aufzählungen
\usepackage{enumitem}

% Code-Listings
\usepackage{xcolor}
\usepackage{listings}
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\lstdefinestyle{code}{
basicstyle=\ttfamily,
columns=fullflexible,
showstringspaces=false,
numbers=left,
numberstyle=\scriptsize,
stepnumber=1,
numbersep=8pt,
backgroundcolor=\color{background},
commentstyle=\color{pgrey}\itshape,
keywordstyle=\color{pblue},
stringstyle=\color{pred},
breaklines=true,
breakatwhitespace=true,
tabsize=2,
keepspaces=true,
linewidth=\textwidth
}

\lstdefinelanguage{json}{
basicstyle=\normalfont\ttfamily,
numbers=left,
numberstyle=\scriptsize,
stepnumber=1,
numbersep=8pt,
showstringspaces=false,
breaklines=true,
backgroundcolor=\color{background},
literate=
*{0}{{{\color{numb}0}}}{1}
{1}{{{\color{numb}1}}}{1}
{2}{{{\color{numb}2}}}{1}
{3}{{{\color{numb}3}}}{1}
{4}{{{\color{numb}4}}}{1}
{5}{{{\color{numb}5}}}{1}
{6}{{{\color{numb}6}}}{1}
{7}{{{\color{numb}7}}}{1}
{8}{{{\color{numb}8}}}{1}
{9}{{{\color{numb}9}}}{1}
{:}{{{\color{punct}{:}}}}{1}
{,}{{{\color{punct}{,}}}}{1}
{\{}{{{\color{delim}{\{}}}}{1}
{\}}{{{\color{delim}{\}}}}}{1}
{[}{{{\color{delim}{[}}}}{1}
{]}{{{\color{delim}{]}}}}{1},
}

\lstdefinelanguage{xml}{
morestring=",
morestring={>}{<},
morecomment={<?}{?>},
stringstyle=\color{black},
identifierstyle=\color{pblue},
keywordstyle=\color{pgreen},
morekeywords={xmlns,version,type}
}

\lstdefinelanguage{Java}{
showspaces=false,
showtabs=false,
tabsize=4,
breaklines=true,
keepspaces=true,
showstringspaces=false,
commentstyle=\color{pgrey}\itshape,
keywordstyle=\color{pblue},
stringstyle=\color{pred},
basicstyle=\ttfamily
}

\lstset{style=code}

%%%%%%%%%%%%%%%%%%%
%% definitions
%%%%%%%%%%%%%%%%%%%
\def\BaAuthor{Noah Raupold (5022097),\\ David Gläsle (5022114)}
\def\BaAuthorPDF{Noah Raupold (5022097), David Gläsle (5022114)}
\def\BaAuthorStudyProgram{Informatik}
\def\BaType{ADT Portfolio Teil 3}
\def\BaTitle{Optimierung des Lobbyregisters}
\def\BaDeadline{\today}

\def\iswithfullname{1}
\ifdefined\iswithfullname
\def\ShowBaAuthor{\BaAuthor}
\else
\def\ShowBaAuthor{N.~N.}
\fi

\newcommand{\TitleGraphic}{%
\IfFileExists{Logo.png}{%
\includegraphics[width=0.5\textwidth]{Logo.png}%
}{%
\fbox{\parbox[c][3cm][c]{0.5\textwidth}{Logo.png fehlt}}%
}%
}

\newcommand*{\forcetwosidetitle}{
\begingroup
\cleardoubleoddpage
\KOMAoptions{titlepage=true}%
\csname @twosidetrue\endcsname
\maketitle
\endgroup
}

\newcommand{\TOCbreak}{\\}

% Bibliografie (Biber)
\usepackage[backend=biber,style=numeric]{biblatex}
\IfFileExists{literatur.bib}{\addbibresource{literatur.bib}}{}

% --- TikZ (nur bei Bedarf) ---
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,calc,fit,backgrounds}
\usepackage{adjustbox} % für max totalsize

% Hyperlinks zuletzt laden
\usepackage{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=black,
filecolor=magenta,
urlcolor=cyan,
pdfauthor={\BaAuthorPDF},
pdftitle={\BaTitle}
}

\begin{document}

%%%%%%%%%%%%%%%%%%%
%% Titelseite
%%%%%%%%%%%%%%%%%%%
\frontmatter
\titlehead{Technische Hochschule Würzburg-Schweinfurt\\Fakultät Informatik und Wirtschaftsinformatik}
\subject{\BaType}
\title{\texorpdfstring{\BaTitle\\[15mm]\TitleGraphic}{\BaTitle}}
% \subtitle{\normalsize{vorgelegt an der Technischen Hochschule W\"{u}rzburg-Schweinfurt in der Fakult\"{a}t Informatik und Wirtschaftsinformatik zum Abschluss eines Studiums im Studiengang \BaAuthorStudyProgram}}
\author{\ShowBaAuthor}
\date{\normalsize{Eingereicht am: \BaDeadline}}
\forcetwosidetitle

%%%%%%%%%%%%%%%%%%%
%% Inhaltsverzeichnis
%%%%%%%%%%%%%%%%%%%
\newpage
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\tableofcontents

%%%%%%%%%%%%%%%%%%%
%% Main part of the thesis
%%%%%%%%%%%%%%%%%%%
\mainmatter
\chapter{Einleitung}

Im vorangegangenen Portfolioteil wurde das Fundament dieses Projekts gelegt: Eine robuste, asynchrone ETL-Pipeline, die zuverlässig tausende Datensätze aus dem Lobbyregister des Deutschen Bundestags extrahiert und in ein streng normalisiertes 3NF-Schema überführt. Doch Datenbesitz allein generiert noch keinen Mehrwert. Der wahre Nutzen entsteht erst durch die Fähigkeit, komplexe Zusammenhänge – etwa finanzielle Verflechtungen oder den Wechsel von Politikern in die Wirtschaft – interaktiv und verzögerungsfrei zu analysieren.

Mit wachsendem Datenvolumen zeigte sich jedoch schnell die Kehrseite der hohen Normalisierung: Analytische Abfragen, die über Dutzende Tabellen verknüpfen, führten zu spürbaren Latenzen. Eine Volltextsuche über Millionen von Namen wurde zum Flaschenhals, und komplexe Netzwerkanalysen waren für ein Echtzeit-Dashboard schlicht zu langsam.

Ziel dieses dritten Portfolioteils ist daher nicht bloßes „Tuning“, sondern die Transformation der Datenbank von einem reinen Datenspeicher zu einer hochperformanten Analytics-Engine. Wir verlagern den Fokus von der logischen Korrektheit (Portfolio 2) auf die physische Effizienz (Portfolio 3). Dabei folgen wir einem strikt methodischen Ansatz: Statt auf gut Glück Indizes zu setzen, analysieren wir Ausführungspläne, messen I/O-Lasten und beweisen den Erfolg jeder Maßnahme durch reproduzierbare „Cold vs. Warm Cache“-Benchmarks.

Das Ergebnis ist eine Datenbank, die selbst komplexe Fragen zum Lobbyismus in Millisekunden beantwortet und damit die technische Basis für transparente, demokratische Kontrolle liefert.

\chapter{Methodik der Performance-Messung}

Performance-Optimierung ist ohne valide Messungen ein Blindflug. Um die Wirksamkeit unserer Maßnahmen objektiv zu bewerten, haben wir uns gegen einfache „Stoppuhr-Messungen“ im Client entschieden, da diese durch Netzwerklatenzen verfälscht werden können. Stattdessen wurde ein automatisiertes Benchmarking-Framework entwickelt (\texttt{scripts/benchmark.py}), das tief in die Interna der PostgreSQL-Engine blickt.

\section{Messverfahren und Metriken}

Unser Ansatz basiert auf drei Säulen der Messbarkeit:

\begin{itemize}
\item \textbf{EXPLAIN (ANALYZE, BUFFERS):} Wir verlassen uns nicht auf Zeitmessungen allein. Durch die Analyse der \textit{Shared Buffers} messen wir exakt, wie viele Datenblöcke von der Festplatte (\textit{Disk Read}) versus aus dem Arbeitsspeicher (\textit{Shared Hit}) geladen wurden. Dies ist eine deutlich stabilere Metrik als die reine Laufzeit, die durch CPU-Last schwanken kann.

\item \textbf{Cold vs. Warm Cache Szenarien:} Ein häufiger Fehler in Datenbank-Benchmarks ist das Ignorieren des Caches. Eine Abfrage, die beim zweiten Aufruf schnell ist, kann beim ersten Aufruf das System blockieren. Unser Mess-Skript erzwingt daher durch Container-Neustarts einen „Cold State“, um den Worst-Case (I/O-Bound) zu simulieren, und misst anschließend den „Warm State“ (CPU-Bound), um die maximal mögliche Geschwindigkeit zu ermitteln.

\item \textbf{Automatisierung und Reproduzierbarkeit:} Um Zufallstreffer auszuschließen, wird der gesamte Benchmark-Prozess durch ein Shell-Skript (\texttt{measure\_full.sh}) gesteuert. Dieses Skript versetzt die Datenbank deterministisch in den Ursprungszustand, führt die Messungen durch, spielt die Optimierungen ein und wiederholt die Messung. Nur so lässt sich der Vorher-Nachher-Effekt wissenschaftlich belegen.
\end{itemize}

\section{Identifikation der Hot-Spots}

Zur Auswahl der zu optimierenden Abfragen („Hot Queries“) haben wir uns an realen Use-Cases orientiert, wie sie in einem analytischen Dashboard auftreten. Dabei wurden gezielt Szenarien gewählt, die die Schwächen eines normalisierten Schemas offenlegen: Aggregationen über viele Tabellen (Finanzen), Textsuche mit Wildcards (Namenssuche) und rekursive Verbindungen (Netzwerkanalysen).

Wir haben sechs Szenarien definiert, die typische Zugriffsmuster abdecken:
\begin{enumerate}
\item \textbf{Finanz-Heatmap:} Aggregation über 5 Tabellen (Klassisches Reporting).
\item \textbf{Top-Lobbyisten:} Sortierung und Filterung großer Mengen.
\item \textbf{Drehtür-Effekt:} Filterung auf spezifische Attribute (ehemalige Regierungsmitglieder).
\item \textbf{Netzwerk-Analyse:} Einfache Joins mit hoher Kardinalität.
\item \textbf{Textsuche:} \texttt{ILIKE '\%Suchbegriff\%'} auf Namensfeldern (sehr teuer ohne Spezialindex).
\item \textbf{Komplexe Netzwerkanalyse:} Ein Szenario, das Daten aus vier verschiedenen Personentabellen (Lobbyist, Vertreter, Betraute, Regierung) zusammenführt.
\end{enumerate}

\chapter{Ausgangssituation: Ist-Analyse}

Die Baseline-Messung auf dem unoptimierten Schema bestätigte unsere theoretischen Bedenken: Während einfache `SELECT`-Abfragen performant liefen, brachen komplexe analytische Operationen in der Leistung ein.

\section{Der Flaschenhals der Textsuche}
Ein zentrales Feature des Lobbyregisters ist die Suche nach Akteuren. Eine SQL-Abfrage wie \texttt{ILIKE '\%Verband\%'} zwingt die Datenbank jedoch zu einem \textit{Sequential Scan}. Das bedeutet, PostgreSQL muss jeden einzelnen Eintrag der Tabelle lesen und den Text vergleichen.
\begin{itemize}
\item \textbf{Beobachtung:} Im Benchmark (Szenario 5) benötigte diese Suche im Schnitt über 5 Millisekunden.
\item \textbf{Problem:} Was bei einem einzelnen Nutzer kaum auffällt, führt bei parallelen Zugriffen zur Überlastung der CPU, da Strings sequenziell verglichen werden müssen. Ein Standard-B-Tree-Index ist hier nutzlos, da das Wildcard-Symbol am Anfang des Suchbegriffs steht.
\end{itemize}

\section{Komplexität im „Drehtür-Effekt“}
Die politisch brisante Frage, welche Lobbyisten früher Regierungsämter innehatten, ist datenbanktechnisch ein Albtraum. Die Informationen sind über vier Tabellen verstreut (\texttt{lobbyist}, \texttt{entrusted\_person}, \texttt{legal\_rep}, \texttt{gov\_function}).
Um diese Liste zu erstellen, musste die Datenbank zur Laufzeit riesige Mengen an Relationen joinen und filtern. Ohne Optimierung ist diese Abfrage für ein interaktives Dashboard ungeeignet, da sie bei wachsenden Datenmengen linear langsamer wird und hohe I/O-Lasten auf dem Speichersystem erzeugt.

\section{Einfluss des Caches}
Unsere Messungen zeigten zudem, dass der „Warm Cache“ zwar die Laufzeit drückte (da Daten im RAM lagen), aber die *CPU-Kosten* hoch blieben. Das System war also ineffizient, selbst wenn es schnell antwortete. Unser Ziel für die Optimierung war daher nicht nur Geschwindigkeit, sondern Effizienz: Wir wollten die Arbeit, die die Datenbank leisten muss, fundamental reduzieren.

\chapter{Optimierte Lösung: Advanced Indexing & Views}

Um die identifizierten Engpässe zu beseitigen, setzten wir auf eine hybride Strategie: Spezialisierte Indizes für flexible Suchanfragen und Materialisierung für statische, rechenintensive Reports.

\section{Trigram-Indizes: Suche neu gedacht}
Statt die Textsuche durch teure Hardware zu beschleunigen, änderten wir die Art des Zugriffs. Durch die PostgreSQL-Erweiterung \texttt{pg\_trgm} werden Textinhalte in 3-Zeichen-Schnipsel (Trigramme) zerlegt. Ein darauf basierender GIN-Index (Generalized Inverted Index) erlaubt es der Datenbank, Teilstrings direkt nachzuschlagen, statt sie zu berechnen.

\begin{lstlisting}[language=sql, caption=Implementierung des GIN-Index für Performante Textsuche]
CREATE EXTENSION IF NOT EXISTS pg_trgm;
-- Ermöglicht Suche nach '%Energy%' ohne Sequential Scan
CREATE INDEX IF NOT EXISTS idx_trgm_lobbyist_name
ON public.lobbyist_identity
USING gin (name_text gin_trgm_ops);
\end{lstlisting}

Diese Maßnahme reduziert die Komplexität der Suche drastisch und entlastet die CPU nahezu vollständig von String-Operationen.

\section{Materialized Views: Das „Drei-Tabellen-Problem“ lösen}
Für die Analyse des „Drehtür-Effekts“ entschieden wir uns bewusst gegen weitere Indizes und für eine \textbf{Materialized View}. Der Grund: Selbst mit perfekten Indizes müssten zur Laufzeit vier Tabellen gejoint werden. Da sich historische Regierungsdaten (wer war 2021 Minister?) niemals ändern, ist es Ressourcenverschwendung, dies bei jedem Dashboard-Aufruf neu zu berechnen.

\begin{lstlisting}[language=sql, caption=Materialized View für Drehtür-Netzwerk]
CREATE MATERIALIZED VIEW IF NOT EXISTS public.mv_revolving_door_network AS
WITH all_gov_people AS (
SELECT entry_id, last_name, first_name, recent_gov_function_id, 'Lobbyist' as role
FROM public.lobbyist_identity WHERE recent_gov_function_present = true
UNION ALL
SELECT li.entry_id, ep.last_name, ep.first_name, ep.recent_gov_function_id, 'Entrusted Person' as role
FROM public.entrusted_person ep ...
-- (Weitere Unions für Legal Representatives)
)
SELECT
re.register_number,
li.name_text as organization_name,
rgf.end_year_month,
cl.de as gov_function_type
FROM all_gov_people p
JOIN ... -- (Joins zu Detailtabellen)
\end{lstlisting}

Diese View wird einmalig (oder periodisch) berechnet. Abfragen darauf sind triviale \texttt{SELECT * FROM view}, was komplexe Joins zur Laufzeit eliminiert.



Die erstellte View \texttt{mv\_revolving\_door\_network} „plättet“ das normalisierte Schema in eine einzige, breite Tabelle.
\begin{itemize}
\item \textbf{Trade-Off:} Wir tauschen Speicherplatz (einige Megabyte) gegen Rechenzeit.
\item \textbf{Ergebnis:} Die Abfrage wird trivial (\texttt{SELECT * FROM view}). Der Datenbank-Optimierer muss keine Join-Strategien mehr berechnen, sondern liest einfach sequenziell aus einer kompakten Struktur.
\end{itemize}
\chapter{Bewertung und Ergebnisse}

Die Implementierung der Optimierungsstrategien führte zu messbaren Leistungssteigerungen, die unsere theoretischen Erwartungen bestätigten und in Teilen sogar übertrafen. Die Ergebnisse validieren den Ansatz, dass Schema-Design und physisches Design (Indizes/Views) Hand in Hand gehen müssen, um eine reaktive User Experience zu gewährleisten.

\section{Analyse der Messergebnisse}

Wie Tabelle 5.1 zeigt, konnten wir die Laufzeiten in den kritischen Bereichen massiv senken.

% Hier wird die externe Tabelle eingebunden
\input{figures/Messergebnisse.tex}

Besonders signifikant ist der Unterschied bei der **Textsuche (Szenario 5)**. Durch den Einsatz des Trigram-Index sank die Laufzeit von $\approx 5$ ms auf $0,18$ ms. Das entspricht einer Beschleunigung um den **Faktor 27**. Was vorher bei vielen gleichzeitigen Nutzern zu einer spürbaren CPU-Last geführt hätte, ist nun im Systemrauschen kaum noch messbar.

Noch dramatischer ist der Effekt bei den komplexen Analysen. Die Nutzung der Materialized View drückte die Antwortzeit auf unter 1 Millisekunde. Im Vergleich zu einer komplexen Join-Operation auf den Rohdaten ermöglicht dies nun eine *Instant-Response* im Frontend.

\section{Visualisierung des Performance-Gewinns}

Um die Größenordnungen der Verbesserung greifbar zu machen, stellt Abbildung \ref{fig:benchmark_chart} die Laufzeiten (Cold Cache) logarithmisch dar.

% Hier wird das externe Diagramm eingebunden
\input{figures/Performance-Vergleich.tex}

Der Balken für die „Textsuche“ ist im optimierten Zustand (grün) kaum noch sichtbar, was die Effizienz des GIN-Index eindrucksvoll belegt. Auch die Netzwerk-Analyse profitiert deutlich von den optimierten Zugriffspfaden.

\section{Interpretation der I/O-Last}
Ein Blick auf die gemessenen I/O-Metriken verrät den wahren Grund für diesen Performance-Schub: Wir haben nicht einfach „schnellere Hardware“ simuliert, sondern die notwendige Arbeit der Datenbank reduziert.
\begin{itemize}
\item Bei der optimierten Textsuche müssen statt eines kompletten Table-Scans (Tausende Blöcke) nur noch **123 Buffer Hits** im Index verarbeitet werden.
\item Die Materialized View reduziert die nötigen Leseoperationen auf **57 Hits**, da die Daten bereits kompakt vorliegen und nicht mühsam aus verstreuten Tabellen zusammengesucht werden müssen.
\end{itemize}
Dies beweist die Nachhaltigkeit der Optimierung: Das System skaliert nun auch bei wachsender Datenmenge effizient.

\section{Praxistest: Visualisierung in Grafana}

Die technische Performance übersetzt sich direkt in User Experience. Wir haben die optimierten Abfragen in ein Grafana-Dashboard integriert, um die Reaktionsfähigkeit unter realen Bedingungen zu testen.

\subsection{Echtzeit-Textsuche}

Abbildung \ref{fig:grafana_search} zeigt das Such-Widget. Der Nutzer sucht hier nach dem Teilstring „Berlin“.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{GIN-Trigram-Suche.png}
\caption{Die Live-Suche im Dashboard. Dank des GIN-Trigram-Index werden Organisationen wie „medianet berlinbrandenburg“ oder „LobbyKreisBerlin“ in Echtzeit gefunden, obwohl der Suchbegriff mitten im Wort vorkommt (\texttt{\%Berlin\%}).}
\label{fig:grafana_search}
\end{figure}

Ohne Optimierung würde eine solche Wildcard-Suche bei jedem Tastenschlag einen Sequential Scan der gesamten Datenbank auslösen, was das Interface träge machen würde. Mit dem GIN-Index erscheint das Ergebnis jedoch verzögerungsfrei, da die Datenbank gezielt nur die passenden Trigramme im Index nachschlägt.

\subsection{Ganzheitliche Netzwerkanalyse}

Abschließend führt Abbildung \ref{fig:dashboard_full} die optimierten Komponenten in einer integrierten Ansicht zusammen. Das Dashboard kombiniert die ultraschnelle Textsuche (links) mit der statistischen Auswertung des „Drehtür-Effekts“ (rechts) und einer detaillierten Auflistung von Personenkarrieren (unten).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{Dashboard_optimized.png}
\caption{Das vollständige Analyse-Dashboard: Durch die Kombination von Trigram-Indizes und Materialized Views werden heterogene Datenquellen – von Freitext bis hin zu komplexen Netzwerkbeziehungen – in einer einzigen, performanten Oberfläche vereint. Die Reaktionszeit des gesamten Dashboards liegt trotz der hohen Informationsdichte im Millisekundenbereich.}
\label{fig:dashboard_full}
\end{figure}

Dieses Beispiel verdeutlicht, dass Performance-Optimierung nicht nur isolierte Abfragen beschleunigt, sondern erst die **Kombination** verschiedener Analysewerkzeuge in einem Dashboard ermöglicht, ohne dass sich Ladezeiten akkumulieren.

\subsection{Komplexe Finanz-Aggregation}

Abbildung \ref{fig:grafana_finance} demonstriert die Leistungsfähigkeit der Materialized Views am Beispiel der Finanzdaten.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{Grafana_finacial_dashboard.png}
\caption{Analyse der Top-Themenfelder nach Budget. Das Balkendiagramm aggregiert Millionenbeträge über Tausende von Lobbyisten. Da die Datenquelle hier die \texttt{mv\_financial\_tops} ist, beträgt die Ladezeit dieses Panels unter 1 Millisekunde.}
\label{fig:grafana_finance}
\end{figure}

Zu sehen sind die Themenfelder mit den höchsten deklarierten Lobby-Ausgaben. Um diese Grafik zu erzeugen, müssten normalerweise fünf Tabellen (\texttt{register\_entry}, \texttt{financial\_expenses}, \texttt{activities}, \texttt{field\_of\_interest}, \texttt{code\_label}) verknüpft und summiert werden.
Durch die Materialisierung dieser Berechnungskette (siehe unterer Teil des Screenshots: „Finanzdaten Tabelle (MV Source)“) wird die komplexe Logik vorweggenommen. Das Dashboard muss lediglich die fertigen Summen (z.B. „EU-Gesetzgebung: 539M €“) auslesen. Dies ermöglicht Managern und Analysten einen sofortigen Überblick über finanzielle Dimensionen, ohne auf Ladebalken warten zu müssen.



\chapter{Fazit und Ausblick}

Die Entwicklung dieses Projekts gleicht einer Evolution in zwei Phasen. Während im zweiten Portfolioteil der Fokus auf einer robusten Architektur lag – geprägt durch eine asynchrone Python-Pipeline und ein striktes 3NF-Schema – hat dieser dritte Teil gezeigt, dass Datenintegrität allein noch keine nutzbare Anwendung schafft. Wir mussten lernen, dass eine „saubere“ Datenbank nicht automatisch eine „schnelle“ Datenbank ist.

\section{Reflexion der Architektur}
Die Kombination aus Python/AsyncIO und PostgreSQL hat sich als extrem stabiles Fundament erwiesen. Doch die Entscheidung für eine strikte dritte Normalform führte, wie die Baseline-Messungen zeigten, zu einem massiven Overhead bei Lesezugriffen.
Die wichtigste Erkenntnis ist daher: \textbf{Performance ist kein Zufallsprodukt, sondern ein bewusster Trade-off.}
Wir haben gelernt, Speicherplatz (durch Indizes und Materialized Views) zu opfern, um Rechenzeit zu gewinnen. Wir haben gelernt, dass eine komplexe Netzwerkanalyse nicht zur Laufzeit geschehen darf, sondern vorbereitet werden muss.

\section{Zusammenfassung der Ergebnisse}
Durch den methodischen Einsatz von \textit{Advanced Indexing} und \textit{Materialization} konnten wir die Schwachstellen des normalisierten Schemas eliminieren, ohne dessen Vorteile (Datenkonsistenz) aufzugeben:
\begin{itemize}
\item Die \textbf{Textsuche} wurde durch GIN-Indizes um den Faktor 20 beschleunigt und ermöglicht nun eine „Google-ähnliche“ Experience.
\item \textbf{Komplexe Reports} (Finanzen, Drehtür-Effekt), die zuvor Sekunden dauerten, sind dank Materialized Views nun im Millisekundenbereich abrufbar.
\end{itemize}
Das Dashboard beweist, dass PostgreSQL auch ohne teure Zusatztechnologien (wie Elasticsearch oder Redis) als Backend für High-Performance-Analytics dienen kann – vorausgesetzt, man nutzt die Werkzeuge der Datenbank-Engine korrekt.

\section{Ausblick}
Das System ist nun technisch reif, aber noch nicht am Ende seiner Möglichkeiten.

\end{document}